{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "    \n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consolidated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = None\n",
    "\n",
    "### Notebook grading\n",
    "import numpy as np\n",
    "x_test = np.array([1, 2, 3, 4])\n",
    "y_test = np.array(0.5)\n",
    "w_test = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "learnrate_test = 0.5\n",
    "\n",
    "h_answer = np.dot(x_test, w_test)\n",
    "if h == h_answer:\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"Try again. `h` is not correct.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
